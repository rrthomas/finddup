#! /usr/bin/perl
#
# finddup - find identical files and do something with them.
#

$VERSION = '3.0';

use strict;
use warnings;

use POSIX;
use File::Find ();
use Digest::MD5;
use Getopt::Long;
use Pod::Usage;

use File::Slurp;
use YAML::Any;
use String::ShellQuote;


# for the convenience of &wanted calls, including -eval statements:
use vars qw(*name *dir *prune);
*name   = *File::Find::name;
*dir    = *File::Find::dir;
*prune  = *File::Find::prune;

use vars qw($RCS_VERSION $VERSION @dir $opt %filelist %md5list);

sub wanted;
sub insert_md5;

GetOptions($opt = {}, qw(help|h version dir=s@ oldresult|o commands|c ignore-perms|i)) || pod2usage 2;
pod2usage(1) if $opt->{help};
if ($opt->{version}) { print "Version: $VERSION\n"; exit 0; }

my @dir = @{$opt->{dir}} if ($opt->{dir});
push @dir, '.' if scalar(@dir) eq 0;

if ($opt->{oldresult}) {
   my $md5 = 0; # Don't need the real hashes in this mode
   my $input = read_file(\*STDIN);
   my $filelists = Load($input);
   $md5list{$md5++} = [[$_->{size}, 0, 0, 0, $_->{files}]] foreach @{$filelists};
} else {
   # Traverse desired directories
   File::Find::find({wanted => \&wanted}, @dir);

   my ($prev, $prev2) = ([-1], [-2]);

   # Now calculate md5sums for each file that has another file of the same
   # size. Afterwards %filelist can be freed.
   foreach (sort {$a->[0] cmp $b->[0]} values(%filelist)) {
      insert_md5($prev) if $_->[0] == $prev->[0] || $prev->[0] == $prev2->[0];
      $prev2 = $prev;
      $prev = $_;
   }
   insert_md5($prev) if $prev->[0] == $prev2->[0];
   %filelist = ();
}

# Now we can output duplicates sorted by size
my @filelists;
foreach (sort {$md5list{$b}->[0]->[0] <=> $md5list{$a}->[0]->[0]} keys(%md5list)) {
   next unless @{$md5list{$_}} > 1 or $opt->{oldresult}; # This file is unique
   my $size = $md5list{$_}->[0]->[0];
   if ($size) { # Do not output zero-length files
      if ($opt->{commands}) {
         my $reffile = shift @{$md5list{$_}->[0]->[4]}; # Don't delete the first file!
         foreach (@{$md5list{$_}}) {
            foreach (@{$_->[4]}) {
               print "rm " . shell_quote($_) . "\n" .
                   "ln " . shell_quote($reffile) . " " . shell_quote($_) . "\n";
            }
         }
      } else {
         my @output;
         foreach (@{$md5list{$_}}) {
            push @output, $_ foreach @{$_->[4]};
         }
         push @filelists, {size => $size, files => \@output};
      }
   }
}
print Dump(\@filelists) if !$opt->{commands};


exit 0;


sub wanted {
   my ($dev,$ino,$mode,$nlink,$uid,$gid,$rdev,$size);

   if ((($dev,$ino,$mode,$nlink,$uid,$gid,$rdev,$size) = lstat($_)) && !($File::Find::prune |= ($dev != $File::Find::topdev)) && -f _) {
      $filelist{$ino} = [$size, $mode, $uid, $gid, []] unless exists $filelist{$ino};
      push @{$filelist{$ino}->[4]}, $name;
   }
}

sub insert_md5 {
   my $file = shift;
   if (open(IN, "<", $file->[4]->[0])) {
      my $check = Digest::MD5->new;
      my $data;
      $check->add($data) while sysread(IN, $data, BUFSIZ);
      close IN;
      my $md5 = $check->hexdigest;
      $md5 .= "\t".$file->[1]."\t".$file->[2]."\t".$file->[3] unless $opt->{'ignore-perms'};
      $md5list{$md5} = [] unless exists $md5list{$md5};
      push @{$md5list{$md5}}, $file;
   } else {
      warn "cannot open file '" . $file->[4]->[0] . "'";
   }
}

__END__

=head1 NAME

finddup - Find identical files and do something with them

=head1 SYNOPSIS

B<finddup> [I<options>...]

 -h, --help             show this help
     --version          show version information
 -d, --dir              specify a directory to check (more than one allowed)
 -o, --oldresult        use previous output of this script (on stdin)
 -c, --commands         output shell commands to link identical files together
 -i, --ignore-perms     do not check that file owner and permissions match

=head1 DESCRIPTION

B<finddup> recursively searches the given directories for duplicate files,
or the working directory if none is given.

Files of size 0 are ignored.

The duplicates found are listed, sorted in descending order of size, in YAML
format, for convenient further processing.  Optionally, shell commands to
hard-link identical files together can be output instead.

=head1 EXAMPLE

Run:

        finddup -d / > /tmp/duplist.yaml

It can take quite a while.  Check B<duplist.yaml>.  For example, perhaps
B</etc/nntpserver> and B</usr/adm/messages> both consist of a single newline
character.  Once you have edited B<duplist.yaml> to your satisfaction, run:

        finddup -o -c < /tmp/duplist.yaml | sh

This hard-links the identical files together.

=head1 AUTHOR

Klaus Ethgen <Klaus@Ethgen.de> and Reuben Thomas <rrt@sc3d.org>.

=cut
